name: Selenium Grid CI/CD Pipeline
on:
  push:
    branches: [ main, develop ]  # Run full pipeline on merges to main/develop
  pull_request:
    branches: [ main, develop ]  # Run dev-only pipeline on PRs targeting main/develop
  schedule:
    # Nightly: Every day at 9 AM UTC (3 AM Central Time)
    - cron: '0 9 * * *'
    # Weekly: Every Sunday at 9 AM UTC (3 AM Central Time)
    - cron: '0 9 * * 0'
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment'
        required: true
        default: 'all'
        type: choice
        options:
          - all      # Run dev â†’ test â†’ prod sequentially
          - dev      # Development environment only
          - test     # Test environment only
          - prod     # Production environment only

      test_type:
        description: 'Test Type'
        required: true
        default: 'fe-only'
        type: choice
        options:
          - fe-only        # FE tests only (current behavior)
          - be-only # BE tests only
          - all            # Both FE and BE tests (run in parallel)

      test_suite:
        description: 'Test Suite'
        required: false
        default: 'smoke'
        type: choice
        options:
          - smoke          # Quick smoke tests
          - ci             # CI test suite
          - extended       # Extended test suite
          - all            # All test suites

      be_test_type:
        description: 'BE Test Type (if test_type includes be)'
        required: false
        default: 'smoke'
        type: choice
        options:
          - smoke          # Quick smoke test (30 seconds, 10 users)
          - all            # All be tests (Gatling + JMeter + Locust)
          - gatling-only   # Gatling only
          - jmeter-only    # JMeter only
          - locust-only    # Locust only

      be_environment:
        description: 'BE Environment (if test_type includes be)'
        required: false
        default: 'dev'
        type: choice
        options:
          - dev      # Development environment only
          - test     # Test environment only
          - dev-test # Both dev and test environments

permissions:
  contents: write  # Required for GitHub Pages deployment

# Prevent redundant runs on the same branch/PR
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

env:
  JAVA_VERSION: '21'
  MAVEN_OPTS: -Xmx2048m -Dorg.slf4j.simpleLogger.log.org.apache.maven.cli.transfer.Slf4jMavenTransferListener=warn
  # Environment URLs - Default ports per ONE_GOAL.md
  # APP: DEV=3003, TEST=3004, PROD=3005
  # API: DEV=8003, TEST=8004, PROD=8005
  BASE_URL_DEV: 'http://localhost:3003'
  BASE_URL_TEST: 'http://localhost:3004'
  BASE_URL_PROD: 'http://localhost:3005'

jobs:
  # ==================================================================================
  # PIPELINE TEMPORARILY DISABLED
  # All jobs disabled while development work is in progress
  # ==================================================================================
  
  # DISABLED: All pipeline jobs temporarily disabled
  # pipeline-disabled:
  #   name: Pipeline Disabled
  #   runs-on: ubuntu-latest
  #   if: false
  #   steps:
  #     - name: Pipeline Disabled Notice
  #       run: |
  #         echo "âš ï¸  All pipeline jobs are temporarily disabled"
  #         echo "This is intentional while development work is in progress"

  # ==================================================================================
  # STAGE 1: CHANGE DETECTION & ENVIRONMENT DETERMINATION
  # ==================================================================================

  detect-file-changes:
    name: Detect File Changes
    runs-on: ubuntu-latest
    outputs:
      code-changed: ${{ steps.filter.outputs.code-changed }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 2

      - name: Detect changed files
        id: filter
        run: |
          chmod +x scripts/ci/detect-changes.sh
          # For scheduled runs, always return 'true' to run tests
          if [ "${{ github.event_name }}" == "schedule" ]; then
            echo "â° Scheduled run detected - forcing code-changed=true"
            echo "code-changed=true" >> "$GITHUB_OUTPUT"
          else
            # Run the script and capture its output
            ./scripts/ci/detect-changes.sh "${{ github.event_name }}" "${{ github.event.pull_request.base.sha }}" "${{ github.sha }}"
          fi
          # Verify output was set correctly
          echo "ðŸ” Verifying code-changed output was set..."
          if [ -f "$GITHUB_OUTPUT" ]; then
            echo "GITHUB_OUTPUT file exists"
            if grep -q "code-changed=" "$GITHUB_OUTPUT"; then
              echo "âœ… code-changed output found in GITHUB_OUTPUT:"
              grep "code-changed=" "$GITHUB_OUTPUT" || true
            else
              echo "âŒ ERROR: code-changed output NOT found in GITHUB_OUTPUT!"
              echo "GITHUB_OUTPUT contents:"
              cat "$GITHUB_OUTPUT" || true
              # Fallback: set it manually if script didn't set it
              echo "âš ï¸ Setting code-changed=true as fallback (code files were detected)"
              echo "code-changed=true" >> "$GITHUB_OUTPUT"
            fi
          else
            echo "âŒ ERROR: GITHUB_OUTPUT file does not exist!"
            # Fallback: set it manually
            echo "âš ï¸ Setting code-changed=true as fallback"
            echo "code-changed=true" >> "$GITHUB_OUTPUT"
          fi

  determine-schedule-type:
    name: Determine Schedule Type
    runs-on: ubuntu-latest
    needs: [detect-file-changes]
    # Always run to ensure outputs are available for downstream jobs
    if: always()
    outputs:
      code-changed: ${{ needs.detect-file-changes.outputs.code-changed || 'true' }}
      is_weekly: ${{ steps.check-day.outputs.is_weekly || 'false' }}
      is_nightly: ${{ steps.check-day.outputs.is_nightly || 'false' }}
      be_test_type: ${{ steps.check-day.outputs.be_test_type || 'smoke' }}
    steps:
      - name: Check day of week (for scheduled runs)
        id: check-day
        run: |
          # For scheduled runs, determine if it's weekly (Sunday) or nightly (other days)
          if [ "${{ github.event_name }}" == "schedule" ]; then
            # Get day of week (0=Sunday, 1=Monday, ..., 6=Saturday)
            DAY_OF_WEEK=$(date -u +%w)
            if [ "$DAY_OF_WEEK" == "0" ]; then
              echo "ðŸ“… Sunday detected - This is a WEEKLY scheduled run"
              {
                echo "is_weekly=true"
                echo "is_nightly=false"
                echo "be_test_type=all"
              } >> "$GITHUB_OUTPUT"
            else
              echo "ðŸŒ™ Not Sunday - This is a NIGHTLY scheduled run"
              {
                echo "is_weekly=false"
                echo "is_nightly=true"
                echo "be_test_type=smoke"
              } >> "$GITHUB_OUTPUT"
            fi
          else
            # Not a scheduled run - set defaults
            echo "ðŸ“¦ Not a scheduled run - setting defaults"
            {
              echo "is_weekly=false"
              echo "is_nightly=false"
              echo "be_test_type=smoke"
            } >> "$GITHUB_OUTPUT"
          fi

  setup-base-urls:
    name: Setup Base URLs
    runs-on: ubuntu-latest
    outputs:
      base_url_dev: ${{ steps.set-urls.outputs.base_url_dev }}
      base_url_test: ${{ steps.set-urls.outputs.base_url_test }}
      base_url_prod: ${{ steps.set-urls.outputs.base_url_prod }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set Base URLs
        id: set-urls
        run: |
          chmod +x scripts/ci/setup-base-urls.sh
          ./scripts/ci/setup-base-urls.sh \
            "${{ env.BASE_URL_DEV }}" \
            "${{ env.BASE_URL_TEST }}" \
            "${{ env.BASE_URL_PROD }}"

  determine-envs:
    name: Determine Environments
    runs-on: ubuntu-latest
    needs: [determine-schedule-type]
    # Always run to ensure outputs are available for downstream jobs
    if: always()
    outputs:
      run_dev: ${{ steps.set-envs.outputs.run_dev || 'true' }}
      run_test: ${{ steps.set-envs.outputs.run_test || 'true' }}
      run_prod: ${{ steps.set-envs.outputs.run_prod || 'true' }}
      test_suite: ${{ steps.set-envs.outputs.test_suite || 'smoke' }}
      selected_env: ${{ steps.set-envs.outputs.selected_env || 'all' }}
      # Test execution controls - same for all environments
      enable_smoke_tests: ${{ steps.set-envs.outputs.enable_smoke_tests || 'false' }}
      enable_grid_tests: ${{ steps.set-envs.outputs.enable_grid_tests || 'false' }}
      enable_mobile_tests: ${{ steps.set-envs.outputs.enable_mobile_tests || 'false' }}
      enable_responsive_tests: ${{ steps.set-envs.outputs.enable_responsive_tests || 'false' }}
      enable_cypress_tests: ${{ steps.set-envs.outputs.enable_cypress_tests || 'true' }}
      enable_playwright_tests: ${{ steps.set-envs.outputs.enable_playwright_tests || 'true' }}
      enable_robot_tests: ${{ steps.set-envs.outputs.enable_robot_tests || 'true' }}
      enable_selenide_tests: ${{ steps.set-envs.outputs.enable_selenide_tests || 'false' }}
      enable_vibium_tests: ${{ steps.set-envs.outputs.enable_vibium_tests || 'true' }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Determine which environments to run
        id: set-envs
        run: |
          chmod +x scripts/ci/determine-environments.sh
          # For scheduled runs, always use 'dev' environment and 'all' test suites
          if [ "${{ github.event_name }}" == "schedule" ]; then
            echo "â° Scheduled run - using dev environment with all test suites"
            ENV_INPUT="dev"
            SUITE_INPUT="all"
          else
            ENV_INPUT="${{ github.event.inputs.environment }}"
            SUITE_INPUT="${{ github.event.inputs.test_suite }}"
          fi
          ./scripts/ci/determine-environments.sh \
            "${{ github.event_name }}" \
            "${{ github.ref }}" \
            "$ENV_INPUT" \
            "$SUITE_INPUT"
          
          # Verify outputs were set
          echo "ðŸ” Verifying determine-envs outputs were set..."
          if [ -f "$GITHUB_OUTPUT" ]; then
            echo "GITHUB_OUTPUT contents:"
            cat "$GITHUB_OUTPUT" | grep -E "(run_dev|run_test|run_prod|enable_cypress_tests)" || echo "âš ï¸  Key outputs not found!"
          else
            echo "âŒ GITHUB_OUTPUT file not found!"
          fi

  determine-test-execution:
    name: Determine Test Execution
    runs-on: ubuntu-latest
    needs: [determine-schedule-type]
    # Always run to ensure outputs are available for downstream jobs
    if: always()
    outputs:
      run_ui_tests: ${{ steps.set-execution.outputs.run_ui_tests || 'true' }}
      run_be_tests: ${{ steps.set-execution.outputs.run_be_tests || 'false' }}
      run_fs_tests: ${{ steps.set-execution.outputs.run_fs_tests || 'false' }}
      be_test_mode: ${{ steps.set-execution.outputs.be_test_mode || 'smoke' }}
      be_env_dev: ${{ steps.set-execution.outputs.be_env_dev || 'false' }}
      be_env_test: ${{ steps.set-execution.outputs.be_env_test || 'false' }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Determine what tests to run
        id: set-execution
        run: |
          chmod +x scripts/ci/determine-test-execution.sh
          # For scheduled runs, always use 'all' test types and schedule-specific be test type
          if [ "${{ github.event_name }}" == "schedule" ]; then
            echo "â° Scheduled run - using all test types"
            TEST_TYPE_INPUT="all"
            # Use be_test_type from determine-schedule-type if available, otherwise default to 'smoke'
            PERF_TYPE_INPUT="${{ needs.determine-schedule-type.outputs.be_test_type || 'smoke' }}"
            PERF_ENV_INPUT="dev"
          elif [ "${{ github.event_name }}" == "workflow_dispatch" ]; then
            # Manual runs: use inputs if provided, otherwise let script use defaults
            TEST_TYPE_INPUT="${{ github.event.inputs.test_type || '' }}"
            PERF_TYPE_INPUT="${{ github.event.inputs.be_test_type || '' }}"
            PERF_ENV_INPUT="${{ github.event.inputs.be_environment || '' }}"
          else
            # Push/PR events: let script determine defaults based on event type and branch
            TEST_TYPE_INPUT=""
            PERF_TYPE_INPUT=""
            PERF_ENV_INPUT=""
          fi
          echo "ðŸ” DEBUG: Test execution inputs:"
          echo "   TEST_TYPE_INPUT: $TEST_TYPE_INPUT"
          echo "   PERF_TYPE_INPUT: $PERF_TYPE_INPUT"
          echo "   PERF_ENV_INPUT: $PERF_ENV_INPUT"
          ./scripts/ci/determine-test-execution.sh \
            "${{ github.event_name }}" \
            "${{ github.ref }}" \
            "$TEST_TYPE_INPUT" \
            "$PERF_TYPE_INPUT" \
            "$PERF_ENV_INPUT"
          
          # Verify outputs were set
          echo "ðŸ” Verifying outputs were set..."
          if [ -f "$GITHUB_OUTPUT" ]; then
            echo "GITHUB_OUTPUT contents:"
            cat "$GITHUB_OUTPUT" | grep -E "(run_ui_tests|run_be_tests|run_fs_tests)" || echo "âš ï¸  No test execution outputs found!"
          else
            echo "âŒ GITHUB_OUTPUT file not found!"
            exit 1
          fi

  # ==================================================================================
  # STAGE 2: SHARED SETUP (Run once for all environments)
  # ==================================================================================
  # Note: All jobs below run in parallel after determine-schedule-type completes.
  # docker-build is listed first as it takes the longest.

  docker-build-test:
    name: Docker Build Test
    runs-on: ubuntu-latest
    needs: [determine-schedule-type]
    if: needs.determine-schedule-type.outputs.code-changed == 'true'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build and load Docker image
        uses: docker/build-push-action@v6
        with:
          context: .
          file: ./Dockerfile
          load: true
          tags: full-stack-qa-tests:latest
          cache-from: type=gha
          cache-to: type=gha,mode=max

      - name: Verify container can run
        continue-on-error: true
        run: |
          chmod +x scripts/ci/verify-docker-image.sh
          ./scripts/ci/verify-docker-image.sh "full-stack-qa-tests:latest"

      - name: Check Docker image size and layers
        if: success()
        run: |
          echo "ðŸ“Š Docker Image Metrics:"
          echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
          docker images full-stack-qa-tests:latest --format "Image: {{.Repository}}:{{.Tag}} | Size: {{.Size}}"
          echo ""
          echo "Layer count:"
          docker history full-stack-qa-tests:latest --format "{{.CreatedBy}}" | wc -l
          echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"

      - name: Extract compiled classes from Docker image
        continue-on-error: true
        run: |
          chmod +x scripts/ci/extract-compiled-classes.sh
          ./scripts/ci/extract-compiled-classes.sh "full-stack-qa-tests:latest" "docker-compiled-classes"

      - name: Upload compiled classes from Docker build
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: compiled-classes-from-docker
          path: docker-compiled-classes/target/
          retention-days: 1
          if-no-files-found: ignore

  build-and-compile:
    name: Build & Compile
    runs-on: ubuntu-latest
    needs: [determine-schedule-type, docker-build-test]
    if: needs.determine-schedule-type.outputs.code-changed == 'true'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up JDK 21
        uses: actions/setup-java@v4
        with:
          java-version: ${{ env.JAVA_VERSION }}
          distribution: 'temurin'
          cache: 'maven'

      - name: Download compiled classes from Docker build
        id: download-docker-classes
        continue-on-error: true
        uses: actions/download-artifact@v4
        with:
          name: compiled-classes-from-docker
          path: docker-compiled-classes

      - name: Use compiled classes or compile if needed
        run: |
          chmod +x scripts/ci/reuse-or-compile.sh
          ./scripts/ci/reuse-or-compile.sh "docker-compiled-classes/target"

      - name: Upload compiled classes
        uses: actions/upload-artifact@v4
        with:
          name: compiled-classes
          path: target/
          retention-days: 1
          if-no-files-found: ignore

  code-quality-analysis:
    name: Code Quality Analysis
    runs-on: ubuntu-latest
    # Note: code-quality does NOT need build-and-compile because:
    # - Checkstyle runs in Maven 'validate' phase (before compile) and analyzes source files only
    # - PMD analyzes source code directly and doesn't require compiled classes
    # - Both tools can run independently and in parallel with compilation
    # Removed validate-test-data dependency - code quality tools don't use test data
    needs: [determine-schedule-type]
    if: needs.determine-schedule-type.outputs.code-changed == 'true'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up JDK 21
        uses: actions/setup-java@v4
        with:
          java-version: ${{ env.JAVA_VERSION }}
          distribution: 'temurin'
          cache: 'maven'

      - name: Run Code Quality Checks
        run: |
          chmod +x scripts/ci/verify-code-quality.sh
          ./scripts/ci/verify-code-quality.sh
        continue-on-error: true
      # DISABLED: Tests temporarily disabled while backend work is in progress

      - name: Upload Analysis Reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: code-quality-reports
          path: |
            target/checkstyle-result.xml
            target/pmd.xml
            target/site/
          retention-days: 1
          if-no-files-found: ignore

  validate-dependency-versions:
    name: Validate Dependency Versions
    runs-on: ubuntu-latest
    # Note: validate-versions does NOT need build-and-compile because:
    # - It only reads configuration files (pom.xml, package.json, requirements.txt, workflow files)
    # - It doesn't require compiled classes or build artifacts
    # - It can run in parallel with other jobs that only need source/configuration files
    needs: [determine-schedule-type]
    if: needs.determine-schedule-type.outputs.code-changed == 'true'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Validate Dependency Versions
        run: |
          chmod +x scripts/validate-dependency-versions.sh
          ./scripts/validate-dependency-versions.sh

  validate-test-data-json:
    name: Validate Test Data (JSON)
    runs-on: ubuntu-latest
    needs: [determine-schedule-type]
    if: needs.determine-schedule-type.outputs.code-changed == 'true'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Install dependencies (if needed)
        run: |
          if [ -f "package.json" ]; then
            npm install ajv ajv-formats --no-save || true
          fi

      - name: Validate test data JSON files
        run: |
          chmod +x scripts/ci/validate-json-data.sh
          ./scripts/ci/validate-json-data.sh

      - name: Check for test data changes
        run: |
          chmod +x scripts/ci/check-test-data-changes.sh
          ./scripts/ci/check-test-data-changes.sh "${{ github.event.before }}" "${{ github.sha }}"

  gate-setup:
    name: Gate (SETUP)
    runs-on: ubuntu-latest
    needs: [determine-schedule-type, determine-envs, validate-test-data-json, code-quality-analysis, docker-build-test, build-and-compile, validate-dependency-versions]
    if: |
      always() && 
      needs.determine-schedule-type.outputs.code-changed == 'true' &&
      !cancelled()
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Check Setup Jobs Status
        run: |
          chmod +x scripts/ci/check-gate-status.sh
          ./scripts/ci/check-gate-status.sh "Setup" \
            "validate-test-data-json:${{ needs.validate-test-data-json.result }}" \
            "code-quality-analysis:${{ needs.code-quality-analysis.result }}" \
            "docker-build-test:${{ needs.docker-build-test.result }}" \
            "build-and-compile:${{ needs.build-and-compile.result }}" \
            "validate-dependency-versions:${{ needs.validate-dependency-versions.result }}"

  # ==================================================================================
  # STAGE 3: DEV ENVIRONMENT TESTING & DEPLOYMENT
  # ==================================================================================

  test-fe-dev:
    name: Test FE (DEV)
    needs: [setup-base-urls, determine-test-execution, determine-envs, gate-setup]
    if: |
      always() &&
      !cancelled() &&
      needs.determine-test-execution.outputs.run_ui_tests == 'true' &&
      needs.determine-envs.outputs.run_dev == 'true' &&
      needs.gate-setup.result == 'success'
    uses: ./.github/workflows/env-fe.yml
    with:
      environment: 'dev'
      test_suite: ${{ needs.determine-envs.outputs.test_suite }}
      base_url: ${{ needs.setup-base-urls.outputs.base_url_dev }}
      enable_smoke_tests: ${{ needs.determine-envs.outputs.enable_smoke_tests == 'true' }}
      enable_grid_tests: ${{ needs.determine-envs.outputs.enable_grid_tests == 'true' }}
      enable_mobile_tests: ${{ needs.determine-envs.outputs.enable_mobile_tests == 'true' }}
      enable_responsive_tests: ${{ needs.determine-envs.outputs.enable_responsive_tests == 'true' }}
      enable_cypress_tests: ${{ needs.determine-envs.outputs.enable_cypress_tests == 'true' }}
      enable_playwright_tests: ${{ needs.determine-envs.outputs.enable_playwright_tests == 'true' }}
      enable_robot_tests: ${{ needs.determine-envs.outputs.enable_robot_tests == 'true' }}
      enable_selenide_tests: ${{ needs.determine-envs.outputs.enable_selenide_tests == 'true' }}
      enable_vibium_tests: ${{ needs.determine-envs.outputs.enable_vibium_tests == 'true' }}

  deploy-dev:
    name: Deploy to DEV
    runs-on: ubuntu-latest
    needs: [setup-base-urls, determine-envs, test-fe-dev, gate-dev]
    # Note: Deploy jobs only run on main branch pushes for safety
    # This prevents accidental deployments from feature branches
    if: |
      always() &&
      needs.determine-envs.outputs.run_dev == 'true' &&
      needs.gate-dev.result == 'success' &&
      github.ref == 'refs/heads/main' &&
      github.event_name == 'push'
    environment:
      name: development
      url: ${{ needs.setup-base-urls.outputs.base_url_dev }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Download test results
        uses: actions/download-artifact@v4
        continue-on-error: true
        with:
          pattern: "*-results-dev"
          path: test-results

      - name: Verify tests passed
        id: verify-tests
        run: |
          chmod +x scripts/ci/verify-test-results.sh
          ./scripts/ci/verify-test-results.sh "test-results" "DEV"

      - name: Deploy to DEV
        if: steps.verify-tests.outputs.tests_passed == 'true'
        run: |
          chmod +x scripts/ci/print-deployment-info.sh
          ./scripts/ci/print-deployment-info.sh \
            "dev" \
            "${{ needs.setup-base-urls.outputs.base_url_dev }}" \
            "${{ github.sha }}"

  gate-dev:
    name: Gate (DEV)
    runs-on: ubuntu-latest
    needs: [determine-schedule-type, determine-envs, determine-test-execution, gate-setup, test-fe-dev, test-be-dev, test-fs-dev]
    if: always() && !cancelled()
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Check DEV Testing Jobs Status
        run: |
          chmod +x scripts/ci/check-gate-status-env.sh
          ./scripts/ci/check-gate-status-env.sh "dev" \
            "gate-setup:${{ needs.gate-setup.result }}" \
            "test-fe-dev:${{ needs.test-fe-dev.result }}" \
            "test-be-dev:${{ needs.test-be-dev.result }}" \
            "test-fs-dev:${{ needs.test-fs-dev.result }}" \
            "determine-schedule-type.code-changed:${{ needs.determine-schedule-type.outputs.code-changed }}" \
            "determine-envs.run_dev:${{ needs.determine-envs.outputs.run_dev }}" \
            "determine-test-execution.run_ui_tests:${{ needs.determine-test-execution.outputs.run_ui_tests }}" \
            "determine-test-execution.run_be_tests:${{ needs.determine-test-execution.outputs.run_be_tests }}" \
            "determine-test-execution.be_env_dev:${{ needs.determine-test-execution.outputs.be_env_dev }}" \
            "determine-test-execution.be_test_mode:${{ needs.determine-test-execution.outputs.be_test_mode }}"

  # ==================================================================================
  # STAGE 4: TEST ENVIRONMENT TESTING & DEPLOYMENT
  # (Only runs if test-fe-dev succeeded or if environment=test only)
  # ==================================================================================

  test-fe-test:
    name: Test FE (TEST)
    needs: [setup-base-urls, determine-envs, determine-test-execution, gate-setup, gate-dev]
    if: |
      always() &&
      !cancelled() &&
      needs.determine-test-execution.outputs.run_ui_tests == 'true' &&
      needs.determine-envs.outputs.run_test == 'true' &&
      needs.gate-setup.result == 'success' &&
      needs.gate-dev.result == 'success'
    uses: ./.github/workflows/env-fe.yml
    with:
      environment: 'test'
      test_suite: ${{ needs.determine-envs.outputs.test_suite }}
      base_url: ${{ needs.setup-base-urls.outputs.base_url_test }}
      enable_smoke_tests: ${{ needs.determine-envs.outputs.enable_smoke_tests == 'true' }}
      enable_grid_tests: ${{ needs.determine-envs.outputs.enable_grid_tests == 'true' }}
      enable_mobile_tests: ${{ needs.determine-envs.outputs.enable_mobile_tests == 'true' }}
      enable_responsive_tests: ${{ needs.determine-envs.outputs.enable_responsive_tests == 'true' }}
      enable_cypress_tests: ${{ needs.determine-envs.outputs.enable_cypress_tests == 'true' }}
      enable_playwright_tests: ${{ needs.determine-envs.outputs.enable_playwright_tests == 'true' }}
      enable_robot_tests: ${{ needs.determine-envs.outputs.enable_robot_tests == 'true' }}
      enable_selenide_tests: ${{ needs.determine-envs.outputs.enable_selenide_tests == 'true' }}
      enable_vibium_tests: ${{ needs.determine-envs.outputs.enable_vibium_tests == 'true' }}

  deploy-test:
    name: Deploy (TEST)
    runs-on: ubuntu-latest
    needs: [setup-base-urls, determine-envs, test-fe-test, gate-test]
    # Note: Deploy jobs only run on main branch pushes for safety
    # This prevents accidental deployments from feature branches
    if: |
      always() &&
      needs.determine-envs.outputs.run_test == 'true' &&
      needs.gate-test.result == 'success' &&
      github.ref == 'refs/heads/main' &&
      github.event_name == 'push'
    environment:
      name: test
      url: ${{ needs.setup-base-urls.outputs.base_url_test }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Download test results
        uses: actions/download-artifact@v4
        continue-on-error: true
        with:
          pattern: "*-results-test"
          path: test-results

      - name: Verify tests passed
        id: verify-tests
        run: |
          chmod +x scripts/ci/verify-test-results.sh
          ./scripts/ci/verify-test-results.sh "test-results" "TEST"

      - name: Deploy to TEST
        if: steps.verify-tests.outputs.tests_passed == 'true'
        run: |
          chmod +x scripts/ci/print-deployment-info.sh
          ./scripts/ci/print-deployment-info.sh \
            "test" \
            "${{ needs.setup-base-urls.outputs.base_url_test }}" \
            "${{ github.sha }}" \
            "dev"

  gate-test:
    name: Gate (TEST)
    runs-on: ubuntu-latest
    needs: [determine-schedule-type, determine-envs, determine-test-execution, gate-dev, test-fe-test, test-be-test, test-fs-test]
    if: always() && !cancelled()
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Check TEST Testing Jobs Status
        run: |
          chmod +x scripts/ci/check-gate-status-env.sh
          ./scripts/ci/check-gate-status-env.sh "test" \
            "gate-dev:${{ needs.gate-dev.result }}" \
            "test-fe-test:${{ needs.test-fe-test.result }}" \
            "test-be-test:${{ needs.test-be-test.result }}" \
            "test-fs-test:${{ needs.test-fs-test.result }}" \
            "determine-schedule-type.code-changed:${{ needs.determine-schedule-type.outputs.code-changed }}" \
            "determine-envs.run_test:${{ needs.determine-envs.outputs.run_test }}" \
            "determine-test-execution.run_ui_tests:${{ needs.determine-test-execution.outputs.run_ui_tests }}" \
            "determine-test-execution.run_be_tests:${{ needs.determine-test-execution.outputs.run_be_tests }}" \
            "determine-test-execution.be_env_test:${{ needs.determine-test-execution.outputs.be_env_test }}" \
            "determine-test-execution.be_test_mode:${{ needs.determine-test-execution.outputs.be_test_mode }}"

  # ==================================================================================
  # STAGE 5: PROD ENVIRONMENT TESTING & DEPLOYMENT
  # (Only runs if test-test-environment succeeded or if environment=prod only)
  # ==================================================================================

  test-fe-prod:
    name: Test FE (PROD)
    needs: [setup-base-urls, determine-envs, determine-test-execution, gate-setup, gate-test]
    if: |
      always() &&
      !cancelled() &&
      needs.determine-test-execution.outputs.run_ui_tests == 'true' &&
      needs.determine-envs.outputs.run_prod == 'true' &&
      needs.gate-setup.result == 'success' &&
      needs.gate-test.result == 'success'
    uses: ./.github/workflows/env-fe.yml
    with:
      environment: 'prod'
      test_suite: ${{ needs.determine-envs.outputs.test_suite }}
      base_url: ${{ needs.setup-base-urls.outputs.base_url_prod }}
      enable_smoke_tests: ${{ needs.determine-envs.outputs.enable_smoke_tests == 'true' }}
      enable_grid_tests: ${{ needs.determine-envs.outputs.enable_grid_tests == 'true' }}
      enable_mobile_tests: ${{ needs.determine-envs.outputs.enable_mobile_tests == 'true' }}
      enable_responsive_tests: ${{ needs.determine-envs.outputs.enable_responsive_tests == 'true' }}
      enable_cypress_tests: ${{ needs.determine-envs.outputs.enable_cypress_tests == 'true' }}
      enable_playwright_tests: ${{ needs.determine-envs.outputs.enable_playwright_tests == 'true' }}
      enable_robot_tests: ${{ needs.determine-envs.outputs.enable_robot_tests == 'true' }}
      enable_selenide_tests: ${{ needs.determine-envs.outputs.enable_selenide_tests == 'true' }}
      enable_vibium_tests: ${{ needs.determine-envs.outputs.enable_vibium_tests == 'true' }}

  deploy-prod:
    name: Deploy (PROD)
    runs-on: ubuntu-latest
    needs: [setup-base-urls, determine-envs, test-fe-prod, gate-prod]
    if: |
      always() &&
      needs.determine-envs.outputs.run_prod == 'true' &&
      needs.gate-prod.result == 'success' &&
      github.ref == 'refs/heads/main' &&
      github.event_name == 'push'
    environment:
      name: production
      url: ${{ needs.setup-base-urls.outputs.base_url_prod }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Download test results
        uses: actions/download-artifact@v4
        continue-on-error: true
        with:
          pattern: "*-results-prod"
          path: test-results

      - name: Verify tests passed
        id: verify-tests
        run: |
          chmod +x scripts/ci/verify-test-results.sh
          ./scripts/ci/verify-test-results.sh "test-results" "PROD"

      - name: Deploy to PROD
        if: steps.verify-tests.outputs.tests_passed == 'true'
        run: |
          chmod +x scripts/ci/print-deployment-info.sh
          ./scripts/ci/print-deployment-info.sh \
            "prod" \
            "${{ needs.setup-base-urls.outputs.base_url_prod }}" \
            "${{ github.sha }}" \
            "test"

  gate-prod:
    name: Gate (PROD)
    runs-on: ubuntu-latest
    needs: [determine-schedule-type, determine-envs, gate-test, test-fe-prod]
    if: always() && !cancelled()
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Check PROD Testing Jobs Status
        run: |
          chmod +x scripts/ci/check-gate-status-env.sh
          ./scripts/ci/check-gate-status-env.sh "prod" \
            "gate-test:${{ needs.gate-test.result }}" \
            "test-fe-prod:${{ needs.test-fe-prod.result }}" \
            "determine-schedule-type.code-changed:${{ needs.determine-schedule-type.outputs.code-changed }}" \
            "determine-envs.run_prod:${{ needs.determine-envs.outputs.run_prod }}"

  # ==================================================================================
  # STAGE 5: BE TESTS (Run in parallel with FE tests)
  # BE tests run in dev/test only (never prod)
  # Uses reusable workflow: env-be.yml
  # ==================================================================================

  test-be-dev:
    name: Test BE (DEV)
    uses: ./.github/workflows/env-be.yml
    needs: [determine-schedule-type, determine-test-execution, determine-envs, setup-base-urls, gate-setup]
    if: |
      always() &&
      !cancelled() &&
      needs.determine-schedule-type.outputs.code-changed == 'true' &&
      needs.determine-test-execution.outputs.run_be_tests == 'true' &&
      needs.determine-test-execution.outputs.be_env_dev == 'true'
    with:
      environment: 'dev'
      be_test_type: ${{ needs.determine-test-execution.outputs.be_test_mode }}
      base_url: ${{ needs.setup-base-urls.outputs.base_url_dev }}
    secrets: inherit

  test-be-test:
    name: Test BE (TEST)
    uses: ./.github/workflows/env-be.yml
    needs: [determine-schedule-type, determine-test-execution, determine-envs, setup-base-urls, gate-setup, gate-dev]
    if: |
      always() &&
      !cancelled() &&
      needs.determine-schedule-type.outputs.code-changed == 'true' &&
      needs.determine-test-execution.outputs.run_be_tests == 'true' &&
      needs.determine-test-execution.outputs.be_env_test == 'true'
    with:
      environment: 'test'
      be_test_type: ${{ needs.determine-test-execution.outputs.be_test_mode }}
      base_url: ${{ needs.setup-base-urls.outputs.base_url_test }}
    secrets: inherit

  # ==================================================================================
  # STAGE 6: FS (FULL-STACK) BROWSER LOAD TESTS (Run in parallel with FE and BE tests)
  # FS tests run in dev/test only (never prod)
  # Uses reusable workflow: env-fs.yml
  # ==================================================================================

  test-fs-dev:
    name: Test FS (DEV)
    uses: ./.github/workflows/env-fs.yml
    needs: [determine-schedule-type, determine-test-execution, determine-envs, setup-base-urls, gate-setup]
    # Note: FS (Full-Stack) tests run when run_fs_tests is true (same as BE tests)
    if: |
      always() &&
      !cancelled() &&
      needs.determine-schedule-type.outputs.code-changed == 'true' &&
      needs.determine-test-execution.outputs.run_fs_tests == 'true' &&
      needs.determine-test-execution.outputs.be_env_dev == 'true'
    with:
      environment: 'dev'
      artillery_test_type: 'smoke'  # Quick smoke test for CI/CD
      base_url: ${{ needs.setup-base-urls.outputs.base_url_dev }}
    secrets: inherit

  test-fs-test:
    name: Test FS (TEST)
    uses: ./.github/workflows/env-fs.yml
    needs: [determine-schedule-type, determine-test-execution, determine-envs, setup-base-urls, gate-setup, gate-dev]
    # Note: FS (Full-Stack) tests run when run_fs_tests is true (same as BE tests)
    if: |
      always() &&
      !cancelled() &&
      needs.determine-schedule-type.outputs.code-changed == 'true' &&
      needs.determine-test-execution.outputs.run_fs_tests == 'true' &&
      needs.determine-test-execution.outputs.be_env_test == 'true'
    with:
      environment: 'test'
      artillery_test_type: 'smoke'  # Quick smoke test for CI/CD
      base_url: ${{ needs.setup-base-urls.outputs.base_url_test }}
    secrets: inherit

  allure-conversion-be:
    name: Convert BE Results to Allure
    runs-on: ubuntu-latest
    needs: [determine-test-execution, determine-envs, test-be-dev, test-be-test]
    if: |
      always() &&
      !cancelled() &&
      needs.determine-test-execution.outputs.run_be_tests == 'true' &&
      (needs.test-be-dev.result == 'success' || needs.test-be-dev.result == 'failure' || needs.test-be-dev.result == 'skipped') &&
      (needs.test-be-test.result == 'success' || needs.test-be-test.result == 'failure' || needs.test-be-test.result == 'skipped')
    outputs:
      has_be_results: ${{ steps.set-output.outputs.has_be_results }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: List available be artifacts (debug)
        if: always()
        run: |
          echo "ðŸ” Checking for be artifacts..."
          echo "Expected artifact patterns:"
          echo "  - gatling-be-results-dev"
          echo "  - jmeter-be-results-dev"
          echo "  - locust-be-results-dev"
          echo "  - gatling-be-results-test"
          echo "  - jmeter-be-results-test"
          echo "  - locust-be-results-test"

      - name: Download BE Test Results (DEV)
        uses: actions/download-artifact@v4
        continue-on-error: true
        with:
          pattern: |
            *-be-results-dev
          path: be-results-dev
          merge-multiple: true

      - name: Download BE Test Results (TEST)
        uses: actions/download-artifact@v4
        continue-on-error: true
        with:
          pattern: |
            *-be-results-test
          path: be-results-test
          merge-multiple: true

      - name: Download BE Test Results (PROD)
        uses: actions/download-artifact@v4
        continue-on-error: true
        with:
          pattern: |
            *-be-results-prod
          path: be-results-prod
          merge-multiple: true

      - name: Convert BE Results to Allure Format (DEV)
        id: convert-be-dev
        continue-on-error: true
        run: |
          if [ -d "be-results-dev" ] && [ "$(find be-results-dev -type f 2>/dev/null | wc -l)" -gt 0 ]; then
            chmod +x scripts/ci/prepare-be-results.sh
            ./scripts/ci/prepare-be-results.sh "be-results-dev" "allure-be-results-dev"
            echo "has_be_results_dev=true" >> "$GITHUB_OUTPUT"
          else
            echo "has_be_results_dev=false" >> "$GITHUB_OUTPUT"
          fi

      - name: Convert BE Results to Allure Format (TEST)
        id: convert-be-test
        continue-on-error: true
        run: |
          if [ -d "be-results-test" ] && [ "$(find be-results-test -type f 2>/dev/null | wc -l)" -gt 0 ]; then
            chmod +x scripts/ci/prepare-be-results.sh
            ./scripts/ci/prepare-be-results.sh "be-results-test" "allure-be-results-test"
            echo "has_be_results_test=true" >> "$GITHUB_OUTPUT"
          else
            echo "has_be_results_test=false" >> "$GITHUB_OUTPUT"
          fi

      - name: Convert BE Results to Allure Format (PROD)
        id: convert-be-prod
        continue-on-error: true
        run: |
          if [ -d "be-results-prod" ] && [ "$(find be-results-prod -type f 2>/dev/null | wc -l)" -gt 0 ]; then
            chmod +x scripts/ci/prepare-be-results.sh
            ./scripts/ci/prepare-be-results.sh "be-results-prod" "allure-be-results-prod"
            echo "has_be_results_prod=true" >> "$GITHUB_OUTPUT"
          else
            echo "has_be_results_prod=false" >> "$GITHUB_OUTPUT"
          fi

      - name: Upload BE Allure Results (DEV)
        uses: actions/upload-artifact@v4
        if: always() && steps.convert-be-dev.outputs.has_be_results_dev == 'true'
        with:
          name: be-allure-results-dev
          path: allure-be-results-dev/
          retention-days: 3
          if-no-files-found: ignore

      - name: Upload BE Allure Results (TEST)
        uses: actions/upload-artifact@v4
        if: always() && steps.convert-be-test.outputs.has_be_results_test == 'true'
        with:
          name: be-allure-results-test
          path: allure-be-results-test/
          retention-days: 3
          if-no-files-found: ignore

      - name: Upload BE Allure Results (PROD)
        uses: actions/upload-artifact@v4
        if: always() && steps.convert-be-prod.outputs.has_be_results_prod == 'true'
        with:
          name: be-allure-results-prod
          path: allure-be-results-prod/
          retention-days: 3
          if-no-files-found: ignore

      - name: Set has_be_results output
        id: set-output
        if: always()
        run: |
          if [ "${{ steps.convert-be-dev.outputs.has_be_results_dev }}" == "true" ] || \
             [ "${{ steps.convert-be-test.outputs.has_be_results_test }}" == "true" ] || \
             [ "${{ steps.convert-be-prod.outputs.has_be_results_prod }}" == "true" ]; then
            echo "has_be_results=true" >> "$GITHUB_OUTPUT"
          else
            echo "has_be_results=false" >> "$GITHUB_OUTPUT"
          fi

  # ==================================================================================
  # STAGE 6: COMBINED REPORTING
  # Aggregates results from all tested environments
  # ==================================================================================

  combined-allure-report:
    name: Combined Allure Report (All Environments)
    runs-on: ubuntu-latest
    needs: [determine-schedule-type, determine-test-execution, determine-envs, test-fe-dev, test-fe-test, test-fe-prod, allure-conversion-be, test-fs-dev, test-fs-test]
    if: |
      always() &&
      !cancelled() &&
      needs.determine-schedule-type.outputs.code-changed == 'true' &&
      (needs.determine-test-execution.outputs.run_ui_tests == 'true' || 
       needs.determine-test-execution.outputs.run_be_tests == 'true')

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: List available test result artifacts (debug)
        if: always()
        run: |
          echo "ðŸ” Checking for test result artifacts..."
          echo "Expected artifact patterns (RAW RESULTS ONLY - not generated reports):"
          echo "  - *-results-dev (contains target/allure-results/ with JSON files)"
          echo "  - *-results-test (contains target/allure-results/ with JSON files)"
          echo "  - *-results-prod (contains target/allure-results/ with JSON files)"
          echo "  - be-allure-results (if be tests ran)"
          echo ""
          echo "Note: We do NOT download allure-report-* artifacts as those are already generated HTML reports"
          echo "      We need the raw JSON results from *-results-* artifacts"

      - name: Download test results (DEV)
        uses: actions/download-artifact@v4
        continue-on-error: true
        with:
          pattern: "*-results-dev"
          path: all-test-results/results-dev
          merge-multiple: true

      - name: Download test results (TEST)
        uses: actions/download-artifact@v4
        continue-on-error: true
        with:
          pattern: "*-results-test"
          path: all-test-results/results-test
          merge-multiple: true

      - name: Download test results (PROD)
        uses: actions/download-artifact@v4
        continue-on-error: true
        with:
          pattern: "*-results-prod"
          path: all-test-results/results-prod
          merge-multiple: true

      - name: Download be allure results (DEV)
        uses: actions/download-artifact@v4
        continue-on-error: true
        with:
          pattern: "be-allure-results-dev"
          path: all-test-results/be-results-dev
          merge-multiple: true

      - name: Download be allure results (TEST)
        uses: actions/download-artifact@v4
        continue-on-error: true
        with:
          pattern: "be-allure-results-test"
          path: all-test-results/be-results-test
          merge-multiple: true

      - name: Download be allure results (PROD)
        uses: actions/download-artifact@v4
        continue-on-error: true
        with:
          pattern: "be-allure-results-prod"
          path: all-test-results/be-results-prod
          merge-multiple: true

      - name: Download Cypress results
        uses: actions/download-artifact@v4
        continue-on-error: true
        with:
          pattern: "cypress-results-*"
          path: all-test-results/cypress-results
          merge-multiple: true

      - name: Download Playwright results
        uses: actions/download-artifact@v4
        continue-on-error: true
        with:
          pattern: "playwright-results-*"
          path: all-test-results/playwright-results
          merge-multiple: true

      - name: Download Robot Framework results
        uses: actions/download-artifact@v4
        continue-on-error: true
        with:
          pattern: "robot-results-*"
          path: all-test-results/robot-results
          merge-multiple: true

      - name: Download Selenide results
        uses: actions/download-artifact@v4
        continue-on-error: true
        with:
          pattern: "selenide-results-*"
          path: all-test-results/selenide-results
          merge-multiple: true

      - name: Download Vibium results
        uses: actions/download-artifact@v4
        continue-on-error: true
        with:
          pattern: "vibium-results-*"
          path: all-test-results/vibium-results
          merge-multiple: true

      - name: Download FS results (DEV)
        uses: actions/download-artifact@v4
        continue-on-error: true
        with:
          pattern: "fs-results-dev"
          path: all-test-results/fs-results-dev
          merge-multiple: true

      - name: Download FS results (TEST)
        uses: actions/download-artifact@v4
        continue-on-error: true
        with:
          pattern: "fs-results-test"
          path: all-test-results/fs-results-test
          merge-multiple: true

      - name: "Debug: Show downloaded artifact structure"
        if: always()
        run: |
          echo "ðŸ“Š Downloaded artifact summary:"
          echo ""
          echo "ðŸ” FS (Full-Stack) Test Results:"
          echo "  Checking fs-results directory:"
          if [ -d "all-test-results/fs-results" ]; then
            echo "    âœ… fs-results directory exists"
            echo "    ðŸ“‚ Directory structure:"
            find all-test-results/fs-results -type d 2>/dev/null | head -20 | while read -r d; do
              echo "      ðŸ“ $d"
            done
            echo ""
            echo "    ðŸ“„ JSON files found:"
            find all-test-results/fs-results -name "*.json" -type f 2>/dev/null | while read -r f; do
              echo "      ðŸ“„ $f"
            done
            echo ""
            echo "    ðŸ“Š File count:"
            find all-test-results/fs-results -name "*.json" -type f 2>/dev/null | wc -l | xargs -I {} echo "      Total JSON files: {}"
          else
            echo "    âŒ fs-results directory NOT found"
          fi
          echo ""
          echo "ðŸ” TestNG-based results (should include Selenide):"
          echo "  DEV environment:"
          find all-test-results/results-dev -name "*-result.json" -path "*/selenide-results-*/*" 2>/dev/null | wc -l | xargs -I {} echo "    Selenide results (in results-dev): {} files"
          find all-test-results/selenide-results -name "*-result.json" 2>/dev/null | wc -l | xargs -I {} echo "    Selenide results (explicit download): {} files"
          find all-test-results/results-dev -type d -path "*/selenide-results-*" 2>/dev/null | while read -r d; do
            echo "    ðŸ“ Found: $d"
            find "$d" -name "*-result.json" 2>/dev/null | wc -l | xargs -I {} echo "      Results: {} files"
          done
          if [ -d "all-test-results/selenide-results" ]; then
            find all-test-results/selenide-results -type d 2>/dev/null | head -5 | while read -r d; do
              echo "    ðŸ“ Selenide artifact: $d"
              find "$d" -name "*-result.json" 2>/dev/null | wc -l | xargs -I {} echo "      Results: {} files"
            done
          fi
          echo ""
          echo "  TEST environment:"
          find all-test-results/results-test -name "*-result.json" -path "*/selenide-results-*/*" 2>/dev/null | wc -l | xargs -I {} echo "    Selenide results: {} files"
          echo ""
          echo "  PROD environment:"
          find all-test-results/results-prod -name "*-result.json" -path "*/selenide-results-*/*" 2>/dev/null | wc -l | xargs -I {} echo "    Selenide results: {} files"
          echo ""
          echo "ðŸ” Framework-specific results:"
          echo "  Cypress: $(find all-test-results/cypress-results -type f 2>/dev/null | wc -l | tr -d ' ') files"
          echo "  Playwright: $(find all-test-results/playwright-results -type f 2>/dev/null | wc -l | tr -d ' ') files"
          echo "  Robot: $(find all-test-results/robot-results -type f 2>/dev/null | wc -l | tr -d ' ') files"
          echo "  Vibium: $(find all-test-results/vibium-results -type f 2>/dev/null | wc -l | tr -d ' ') files"
          echo ""
          echo "ðŸ“‚ All artifact directories:"
          find all-test-results -type d -maxdepth 2 2>/dev/null | sort
          chmod +x scripts/ci/debug-artifact-structure.sh
          ./scripts/ci/debug-artifact-structure.sh "all-test-results"

      - name: Prepare combined Allure results
        if: always()
        run: |
          chmod +x scripts/ci/prepare-combined-allure-results.sh
          ./scripts/ci/prepare-combined-allure-results.sh "all-test-results" "allure-results-combined"

      - name: Download Previous Allure History (Artifact Fallback)
        if: always() && github.ref == 'refs/heads/main'
        continue-on-error: true
        id: download-history-artifact
        run: |
          set -e
          echo "ðŸ“¥ Downloading Allure history from previous successful run..."
          echo ""
          
          # Find the previous successful run on main (excluding current run)
          PREVIOUS_RUN_ID=$(gh run list --workflow "Selenium Grid CI/CD Pipeline" --branch main --status success --limit 2 --json databaseId --jq '.[] | select(.databaseId != ${{ github.run_id }}) | .databaseId' | head -1)
          
          if [ -z "$PREVIOUS_RUN_ID" ]; then
            echo "â„¹ï¸  No previous successful run found (this is expected for first run)"
            echo "   History will be created during report generation"
            exit 0
          fi
          
          echo "   Previous run ID: $PREVIOUS_RUN_ID"
          echo ""
          
          # Create history directory
          mkdir -p allure-results-combined/history
          
          # Download artifact from previous run
          if gh run download "$PREVIOUS_RUN_ID" --name allure-history --dir allure-results-combined/history/ 2>/dev/null; then
            FILE_COUNT=$(find allure-results-combined/history -type f 2>/dev/null | wc -l | tr -d ' ')
            if [ "$FILE_COUNT" -gt 0 ]; then
              echo "âœ… Successfully downloaded history from previous run: $FILE_COUNT file(s)"
              echo "   History will be merged with new results during report generation"
            else
              echo "âš ï¸  Artifact downloaded but directory is empty"
              echo "   This may indicate no history was uploaded in previous run"
            fi
          else
            echo "â„¹ï¸  No history artifact found in previous run (expected for first few runs)"
            echo "   History will be created during report generation"
            exit 0
          fi
        env:
          GH_TOKEN: ${{ github.token }}

      - name: Download Previous Allure History (GitHub Pages)
        if: always() && github.ref == 'refs/heads/main'
        run: |
          chmod +x scripts/ci/download-allure-history.sh
          if ! ./scripts/ci/download-allure-history.sh "allure-results-combined" "pages"; then
            echo "âŒ ERROR: History download from GitHub Pages failed"
            exit 1
          fi

      - name: Verify History Download
        if: always() && github.ref == 'refs/heads/main'
        run: |
          set -e
          echo "ðŸ” Verifying history download..."
          echo ""
          
          if [ -d "allure-results-combined/history" ]; then
            echo "âœ… History directory exists"
            FILE_COUNT=$(find allure-results-combined/history -type f 2>/dev/null | wc -l | tr -d ' ')
            if [ "$FILE_COUNT" -gt 0 ]; then
              echo "   Files: $FILE_COUNT file(s)"
              echo "   Size: $(du -sh allure-results-combined/history 2>/dev/null | cut -f1 || echo 'unknown')"
              echo "   Sample files:"
              find allure-results-combined/history -type f -name "*.json" 2>/dev/null | head -5 | while read -r f; do
                echo "     - $(basename "$f")"
              done
              echo ""
              echo "âœ… History download verified successfully"
            else
              # Empty history directory - this is only acceptable for the very first run
              # After that, history should exist from previous runs
              echo "   âš ï¸  Directory is empty"
              echo ""
              echo "   Checking if this is the first run..."
              # Try to determine if history should exist by checking GitHub Pages
              if curl -f -s -I "https://cscharer.github.io/full-stack-qa/history" > /dev/null 2>&1; then
                echo "   âŒ ERROR: History directory exists in GitHub Pages but download failed or is empty"
                echo "   This indicates a problem with history download that must be fixed"
                exit 1
              else
                echo "   â„¹ï¸  No history in GitHub Pages (expected for first run)"
                echo "   History will be created during report generation"
              fi
            fi
          else
            echo "â„¹ï¸  No history directory found"
            # Check if history should exist
            if curl -f -s -I "https://cscharer.github.io/full-stack-qa/history" > /dev/null 2>&1; then
              echo "   âŒ ERROR: History exists in GitHub Pages but directory was not created"
              echo "   This indicates a problem with history download that must be fixed"
              exit 1
            else
              echo "   â„¹ï¸  No history in GitHub Pages (expected for first run)"
              echo "   History will be created during report generation"
            fi
          fi

      - name: Install Allure3 CLI
        if: always()
        run: |
          chmod +x scripts/ci/install-allure3-cli.sh
          ./scripts/ci/install-allure3-cli.sh "3.0.0"

      - name: Generate Combined Allure Report
        if: always()
        run: |
          chmod +x scripts/ci/generate-combined-allure-report.sh
          ./scripts/ci/generate-combined-allure-report.sh "allure-results-combined" "allure-report-combined"

      - name: Verify History in Report
        if: always()
        run: |
          set -e
          echo "ðŸ” Verifying history in generated report..."
          echo ""
          
          if [ -d "allure-report-combined/history" ]; then
            echo "âœ… History directory exists in report"
            FILE_COUNT=$(find allure-report-combined/history -type f ! -name ".gitkeep" 2>/dev/null | wc -l | tr -d ' ')
            echo "   Files: $FILE_COUNT file(s)"
            if [ "$FILE_COUNT" -gt 0 ]; then
              echo "   Size: $(du -sh allure-report-combined/history 2>/dev/null | cut -f1 || echo 'unknown')"
              echo "   Sample files:"
              find allure-report-combined/history -type f -name "*.json" 2>/dev/null | head -5 | while read -r f; do
                echo "     - $(basename "$f")"
              done
              echo ""
              echo "âœ… History will be preserved in GitHub Pages deployment"
            else
              # Empty history directory - this is expected for first few runs
              echo "   â„¹ï¸  History directory exists but appears empty"
              echo "   Allure3 will populate it in subsequent runs"
            fi
          else
            # No history directory - this is expected for first few runs
            # Allure3 creates history naturally after 2-3 runs when it has enough data
            echo "â„¹ï¸  No history directory in generated report"
            echo "   This is expected - Allure3 creates history naturally after 2-3 runs"
            echo "   History will appear when Allure3 has enough test execution data"
            echo "   Previous empty history files in GitHub Pages will be replaced naturally"
          fi

      - name: Upload Allure History (for next run)
        id: upload-history-check
        if: always() && github.ref == 'refs/heads/main'
        run: |
          set -e
          echo "ðŸ“¤ Uploading Allure history for next run..."
          echo ""
          
          if [ -d "allure-report-combined/history" ]; then
            # Count history files (excluding .gitkeep)
            HISTORY_FILE_COUNT=$(find allure-report-combined/history -type f ! -name ".gitkeep" 2>/dev/null | wc -l | tr -d ' ')
            
            if [ "$HISTORY_FILE_COUNT" -gt 0 ]; then
              # History has actual files
              echo "âœ… History directory contains $HISTORY_FILE_COUNT file(s)"
              echo "   Size: $(du -sh allure-report-combined/history 2>/dev/null | cut -f1 || echo 'unknown')"
              echo "   History will be preserved for next run"
              
              # Prepare artifact directory
              mkdir -p allure-history
              cp -r allure-report-combined/history/* allure-history/ 2>/dev/null || true
              echo "   âœ… History artifact ready for upload"
            else
              # Empty history directory - this is expected for first few runs
              echo "â„¹ï¸  History directory exists but is empty"
              echo "   Allure3 will populate it in subsequent runs"
              echo "   No artifact upload needed (empty history will be created naturally)"
            fi
          else
            # No history directory - this is expected for first few runs
            # Allure3 creates history naturally after 2-3 runs
            echo "â„¹ï¸  No history directory in report (expected for first few runs)"
            echo "   Allure3 will create history naturally after 2-3 more runs"
            echo "   History will appear when Allure3 has enough test execution data"
            echo "   No artifact upload needed"
          fi
          
      - name: Upload Allure History Artifact
        uses: actions/upload-artifact@v4
        if: always() && github.ref == 'refs/heads/main' && steps.upload-history-check.outcome == 'success'
        with:
          name: allure-history
          path: allure-history/
          retention-days: 90
          if-no-files-found: ignore

      - name: Upload Combined Allure Report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: allure-report-combined-all-environments
          path: allure-report-combined/
          retention-days: 3
          if-no-files-found: ignore

      - name: Upload Combined Allure Results (for analysis)
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: allure-results-combined-all-environments
          path: allure-results-combined/
          retention-days: 3
          if-no-files-found: ignore

      - name: Check GitHub Pages Deployment Conditions
        if: always()
        run: |
          echo "ðŸ” Checking GitHub Pages deployment conditions..."
          echo ""
          echo "Current branch: ${{ github.ref }}"
          echo "Required branch: refs/heads/main"
          echo "Code changed: ${{ needs.determine-schedule-type.outputs.code-changed }}"
          echo ""
          if [ "${{ github.ref }}" != "refs/heads/main" ]; then
            echo "â­ï¸  GitHub Pages deployment skipped: Not on main branch"
            echo "   (This is expected for feature branches)"
          elif [ "${{ needs.determine-schedule-type.outputs.code-changed }}" != "true" ]; then
            echo "â­ï¸  GitHub Pages deployment skipped: No code changes detected"
          else
            echo "âœ… All conditions met - GitHub Pages will be deployed"
          fi
          echo ""
          echo "ðŸ“¥ Report is still available as artifact: 'allure-report-combined-all-environments'"

      - name: Verify Report Before Deployment
        if: always() && github.ref == 'refs/heads/main' && needs.determine-schedule-type.outputs.code-changed == 'true'
        run: |
          echo "ðŸ” Verifying report structure before deployment..."
          echo ""
          if [ ! -d "allure-report-combined" ]; then
            echo "âŒ Report directory does not exist!"
            echo ""
            echo "Possible causes:"
            echo "  1. Report generation step failed"
            echo "  2. Report generation step was skipped"
            echo "  3. Directory was not created by generate script"
            echo ""
            echo "Checking previous step status..."
            echo "   Generate Combined Allure Report step should have created this directory"
            echo ""
            echo "âš ï¸  Skipping deployment verification - report not available"
            echo "   Report may still be available as artifact: 'allure-report-combined-all-environments'"
            exit 0  # Don't fail the workflow, just skip verification
          fi
          
          if [ -d "allure-report-combined" ]; then
            echo "âœ… Report directory exists"
            echo "   Total files: $(find allure-report-combined -type f | wc -l | tr -d ' ')"
            echo "   Total size: $(du -sh allure-report-combined | cut -f1)"
            echo ""
            echo "ðŸ“Š Checking critical files..."
            echo "   index.html: $([ -f "allure-report-combined/index.html" ] && echo "âœ… exists" || echo "âŒ missing")"
            echo "   data/ directory: $([ -d "allure-report-combined/data" ] && echo "âœ… exists ($(find allure-report-combined/data -type f | wc -l | tr -d ' ') files)" || echo "âŒ missing")"
            echo "   widgets/ directory: $([ -d "allure-report-combined/widgets" ] && echo "âœ… exists ($(find allure-report-combined/widgets -type f | wc -l | tr -d ' ') files)" || echo "âŒ missing")"
            echo ""
            echo "ðŸ“¦ Checking container files in data..."
            if [ -d "allure-report-combined/data" ]; then
              container_count=$(find allure-report-combined/data -name "*-container.json" 2>/dev/null | wc -l | tr -d ' ')
              result_count=$(find allure-report-combined/data -name "*-result.json" 2>/dev/null | wc -l | tr -d ' ')
              echo "   Container files: $container_count"
              echo "   Result files: $result_count"
              echo ""
              echo "   Sample container files (first 10):"
              find allure-report-combined/data -name "*-container.json" 2>/dev/null | head -10 | while read -r f; do
                name=$(jq -r '.name' "$f" 2>/dev/null || echo "unknown")
                echo "     - $(basename "$f"): $name"
              done
            fi
            echo ""
            echo "ðŸ” Checking for framework-specific data..."
            for framework in "Cypress" "Playwright" "Robot" "Vibium" "Selenide" "Surefire"; do
              count=$(find allure-report-combined/data -name "*-container.json" -type f -exec grep -l "$framework" {} + 2>/dev/null | wc -l | tr -d ' ')
              if [ "$count" -gt 0 ]; then
                echo "   âœ… $framework: $count container file(s) found"
              else
                echo "   âš ï¸  $framework: No container files found"
              fi
            done
          else
            echo "âŒ Report directory does not exist!"
            exit 1
          fi

      - name: Deploy to GitHub Pages
        if: always() && github.ref == 'refs/heads/main' && needs.determine-schedule-type.outputs.code-changed == 'true'
        uses: peaceiris/actions-gh-pages@v4
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./allure-report-combined
          keep_files: true
          force_orphan: false
          user_name: 'github-actions[bot]'
          user_email: 'github-actions[bot]@users.noreply.github.com'

      - name: Report Info
        if: always()
        run: |
          echo "ðŸ“Š Combined Allure Report Generated!"
          echo ""
          
          # Show diagnostic information
          if [ -d "allure-report-combined" ]; then
            echo "âœ… Report directory exists"
            echo "   Files: $(find allure-report-combined -type f | wc -l | tr -d ' ')"
            echo "   Size: $(du -sh allure-report-combined | cut -f1)"
            
            # Check if report has test data
            if [ -f "allure-report-combined/index.html" ]; then
              echo "âœ… Report index.html exists"
            else
              echo "âŒ Report index.html missing!"
            fi
          else
            echo "âŒ Report directory does not exist!"
          fi
          
          echo ""
          if [ "${{ github.ref }}" = "refs/heads/main" ]; then
            echo "ðŸŒ View online at:"
            echo "https://${{ github.repository_owner }}.github.io/${{ github.event.repository.name }}/"
            echo ""
            echo "â„¹ï¸  Note: GitHub Pages only updates on main branch when code changes"
          else
            echo "â„¹ï¸  Note: GitHub Pages deployment only happens on main branch"
            echo "   Current branch: ${{ github.ref }}"
          fi
          echo ""
          echo "ðŸ“¥ Download 'allure-report-combined-all-environments' artifact to view the report"

  # ==================================================================================
  # STAGE 7: PIPELINE SUMMARY
  # Always runs to show what was executed
  # ==================================================================================

  pipeline-summary:
    name: Pipeline Summary
    runs-on: ubuntu-latest
    needs: [determine-schedule-type, determine-test-execution, determine-envs, test-fe-dev, deploy-dev, test-fe-test, deploy-test, test-fe-prod, deploy-prod, combined-allure-report, test-be-dev, test-be-test, test-fs-dev, test-fs-test, allure-conversion-be]
    if: always()

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Download Combined Allure Results (for test counts)
        if: always() && needs.combined-allure-report.result == 'success'
        uses: actions/download-artifact@v4
        continue-on-error: true
        with:
          name: allure-results-combined-all-environments
          path: allure-results-combined

      - name: Download Test Results for DEV (for accurate counts)
        if: always() && needs.determine-envs.outputs.run_dev == 'true'
        uses: actions/download-artifact@v4
        continue-on-error: true
        with:
          pattern: '*-results-dev'
          merge-multiple: true
          path: test-results-dev

      - name: Download Test Results for TEST (for accurate counts)
        if: always() && needs.determine-envs.outputs.run_test == 'true'
        uses: actions/download-artifact@v4
        continue-on-error: true
        with:
          pattern: '*-results-test'
          merge-multiple: true
          path: test-results-test

      - name: Download Test Results for PROD (for accurate counts)
        if: always() && needs.determine-envs.outputs.run_prod == 'true'
        uses: actions/download-artifact@v4
        continue-on-error: true
        with:
          pattern: '*-results-prod'
          merge-multiple: true
          path: test-results-prod

      - name: Generate Pipeline Summary
        run: |
          chmod +x scripts/ci/generate-pipeline-summary.sh
          ./scripts/ci/generate-pipeline-summary.sh \
            "$GITHUB_STEP_SUMMARY" \
            "${{ needs.determine-schedule-type.outputs.code-changed }}" \
            "${{ github.event.inputs.test_type || 'fe-only' }}" \
            "${{ needs.determine-envs.outputs.selected_env }}" \
            "${{ needs.determine-envs.outputs.test_suite }}" \
            "${{ needs.determine-test-execution.outputs.run_be_tests }}" \
            "${{ needs.determine-test-execution.outputs.be_test_mode }}" \
            "${{ needs.determine-envs.outputs.run_dev }}" \
            "${{ needs.determine-envs.outputs.run_test }}" \
            "${{ needs.determine-envs.outputs.run_prod }}" \
            "${{ needs.determine-test-execution.outputs.be_env_dev }}" \
            "${{ needs.determine-test-execution.outputs.be_env_test }}" \
            "${{ needs.test-fe-dev.result }}" \
            "${{ needs.test-fe-test.result }}" \
            "${{ needs.test-fe-prod.result }}" \
            "${{ needs.test-be-dev.result }}" \
            "${{ needs.test-be-test.result }}" \
            "${{ needs.test-fs-dev.result }}" \
            "${{ needs.test-fs-test.result }}"
